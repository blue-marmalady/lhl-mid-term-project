{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor, plot_importance \n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from numpy import mean, std\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, shapiro, kstest\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Display all the columns\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleanflight.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.cat_delay.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_var = df.drop(['arr_delay','cat_delay'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_var, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# make sure to do same pre-processing to testing data as well.\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6421194431971262\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_pca)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.6421194431971262.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78     15877\n",
      "           1       0.42      0.04      0.08      8620\n",
      "\n",
      "    accuracy                           0.64     24497\n",
      "   macro avg       0.53      0.51      0.43     24497\n",
      "weighted avg       0.57      0.64      0.53     24497\n",
      "\n",
      "[[15366   511]\n",
      " [ 8256   364]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 3, got 16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\k_mah\\Documents\\mid-term-project-I-master\\xgboost_classifier.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/k_mah/Documents/mid-term-project-I-master/xgboost_classifier.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, y_pred))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/k_mah/Documents/mid-term-project-I-master/xgboost_classifier.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(confusion_matrix(y_test, y_pred))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/k_mah/Documents/mid-term-project-I-master/xgboost_classifier.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mROC-AUC Score: \u001b[39m\u001b[39m{\u001b[39;00mroc_auc_score(y_test, model\u001b[39m.\u001b[39mpredict_proba(X_test)[:,\u001b[39m1\u001b[39m])\u001b[39m:\u001b[39;00m\u001b[39m.16f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\k_mah\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1512\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[1;34m(self, X, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulti:softmax\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1505\u001b[0m     \u001b[39m# We need to run a Python implementation of softmax for it.  Just ask user to\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m     \u001b[39m# use softprob since XGBoost's implementation has mitigation for floating\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m     \u001b[39m# point overflow.  No need to reinvent the wheel.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1509\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmulti:softmax doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt support `predict_proba`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1510\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSwitch to `multi:softproba` instead\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1511\u001b[0m     )\n\u001b[1;32m-> 1512\u001b[0m class_probs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m   1513\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1514\u001b[0m     ntree_limit\u001b[39m=\u001b[39;49mntree_limit,\n\u001b[0;32m   1515\u001b[0m     validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   1516\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1517\u001b[0m     iteration_range\u001b[39m=\u001b[39;49miteration_range\n\u001b[0;32m   1518\u001b[0m )\n\u001b[0;32m   1519\u001b[0m \u001b[39m# If model is loaded from a raw booster there's no `n_classes_`\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \u001b[39mreturn\u001b[39;00m _cls_predict_proba(\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_classes_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m), class_probs, np\u001b[39m.\u001b[39mvstack)\n",
      "File \u001b[1;32mc:\\Users\\k_mah\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1049\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1048\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[0;32m   1050\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1051\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m   1052\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1053\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m   1054\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1055\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   1056\u001b[0m         )\n\u001b[0;32m   1057\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1058\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m     \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\k_mah\\anaconda3\\lib\\site-packages\\xgboost\\core.py:2128\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2124\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2125\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2126\u001b[0m         )\n\u001b[0;32m   2127\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features() \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m-> 2128\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2129\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape mismatch, expected: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features()\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2130\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2131\u001b[0m         )\n\u001b[0;32m   2133\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m   2134\u001b[0m     _is_pandas_df,\n\u001b[0;32m   2135\u001b[0m     _transform_pandas_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2138\u001b[0m     _array_interface,\n\u001b[0;32m   2139\u001b[0m )\n\u001b[0;32m   2140\u001b[0m enable_categorical \u001b[39m=\u001b[39m _has_categorical(\u001b[39mself\u001b[39m, data)\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 3, got 16"
     ]
    }
   ],
   "source": [
    "print(f'The accuracy is {accuracy_score(y_test, y_pred):.16f}.')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(f'ROC-AUC Score: {roc_auc_score(y_test, model.predict_proba(X_test)[:,1]):.16f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0d89b5f63db5632f8f002f79a09b21938afa1ab48b28293f9c2c3a2f99e497b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
